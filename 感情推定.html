<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8" />
  <title>日本語 感情推定（WebLLM・完全クライアント）</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    body{font-family:system-ui, sans-serif; margin:20px}
    textarea{width:100%;height:150px;font-size:16px}
    .panel{border:1px solid #ddd;border-radius:8px;padding:12px;margin-top:12px}
    .mono{font-family:ui-monospace, SFMono-Regular, Menlo, monospace;white-space:pre-wrap}
    .badge{display:inline-block;padding:2px 8px;border-radius:12px;background:#eee}
    .muted{color:#666;font-size:12px}
    .err{color:#c00;white-space:pre-wrap}
    progress{width:100%}
  </style>
</head>
<body>
  <h1>日本語 感情推定（WebLLM / Qwen2.5-0.5B）</h1>

  <div class="panel">
    <div>モデル読み込み進捗</div>
    <progress id="prog" max="1" value="0"></progress>
    <div id="status" class="muted">初期化中…（初回は数百MBのダウンロードが発生）</div>
  </div>

  <label for="text">テキスト</label>
  <textarea id="text" placeholder="例）今日は最高の気分だ。でも少し不安もある。"></textarea>
  <div class="muted">※ 入力停止から約300msでブラウザ内LLMが推定。通信はモデル取得時のみ。</div>

  <div class="panel">
    <div>判定: <span id="label" class="badge">-</span></div>
    <div>score: <span id="score" class="mono">-</span></div>
    <hr>
    <div>理由:</div>
    <pre id="reasons" class="mono">-</pre>
    <hr>
    <div>生出力:</div>
    <pre id="raw" class="mono">-</pre>
    <div class="err" id="err"></div>
  </div>

  <!-- WebLLM（CDN） -->
  <script src="https://unpkg.com/@mlc-ai/web-llm/dist/webllm.min.js"></script>
  <script>
    // -------------------------------
    // 設定
    // -------------------------------
    // 小型・日本語OK・API不要。WebGPU推奨（未対応はWASMで遅くなる）
    const MODEL = "Qwen2.5-0.5B-Instruct-q4f16_1";
    // 他候補: "Qwen2.5-1.5B-Instruct-q4f16_1"（精度↑/容量↑）

    // 出力フォーマットを固定して安定化
    const SYS = `
あなたは感情分析器。入力文の全体的な感情を次のJSONだけで出力。
{"label":"POSITIVE|NEGATIVE|NEUTRAL","score":-1.0〜1.0,"reasons":"日本語の簡潔な根拠"}
余計な文章は出力しない。
`.trim();

    // -------------------------------
    // 要素参照
    // -------------------------------
    const $ = id => document.getElementById(id);
    const prog=$('prog'), status=$('status');
    const t=$('text'), labelEl=$('label'), scoreEl=$('score'), reasonsEl=$('reasons'), rawEl=$('raw'), errEl=$('err');

    // -------------------------------
    // モデル初期化
    // -------------------------------
    let engine=null;
    init();
    async function init(){
      try{
        status.textContent = 'モデル初期化中…';
        engine = await webllm.CreateMLCEngine(MODEL, {
          // 進捗表示
          onProgress: (p) => {
            if (typeof p === 'number') { prog.value = p; status.textContent = `ダウンロード中… ${Math.round(p*100)}%`; }
            else if (p?.text) { status.textContent = p.text; }
          },
        });
        status.textContent = '準備完了';
        // 初回ウォームアップ（短文でプロンプト整形）
        await analyzeOnce('テスト');
      }catch(e){
        errEl.textContent = '初期化失敗: ' + e;
      }
    }

    // -------------------------------
    // 推定（1回）
    // -------------------------------
    async function analyzeOnce(text){
      if (!engine) throw new Error('engine not ready');
      const user = `入力文:\n${text}`;
      const prompt = [
        { role: "system", content: SYS },
        { role: "user", content: user }
      ];
      // 生成
      const out = await engine.chat.completions.create({
        messages: prompt,
        temperature: 0.1,
        max_tokens: 200,
      });
      const content = out.choices?.[0]?.message?.content ?? '';
      rawEl.textContent = content || '(空)';
      // JSON抽出
      let parsed=null;
      try { parsed = JSON.parse(content); }
      catch {
        const m = content.match(/{[\s\S]*}/);
        if (m) { try{ parsed = JSON.parse(m[0]); }catch{} }
      }
      if (!parsed) throw new Error('JSON抽出に失敗: ' + content);

      const L = String(parsed.label||'').toUpperCase();
      const label = L.includes('POS') ? 'POSITIVE' : L.includes('NEG') ? 'NEGATIVE' :
